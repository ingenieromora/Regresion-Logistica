{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva ROC ( Receiver Operating Characteristic )\n",
    "\n",
    "## Modificación del umbral de decisión\n",
    "\n",
    "- Un modelo probabilístico calcula la probabildad de que una observación pertenezca a una clase.\n",
    "- Hasta ahora en clasificación binaria, modelamos $P(Y=1|X=X_i)$. Si esta probabilidad está por encima de 0.5, clasificamos a $X_i$ como perteneciente a la clase 1 o 0 en caso contrario.\n",
    "- Una vez que realizamos la asignación de clases podemos armar la matriz de confusión, y de la matriz de confusión, calcular los diversos indicadores de performance del modelo.\n",
    "\n",
    "¿Podemos armar distintas matrices de confusión, modificando el umbral de clasificación?\n",
    "\n",
    "Podemos, y esto dará origen a distintos modelos, cada uno con su propia matriz de confusión y por lo tanto, distintos valores de sensibilidad, especificidad, etc. \n",
    "\n",
    "Armemos un dataset sintético para analizar cómo varían los parámetros de performance del modelo (calculados a partir de la matriz de confusión) en función del umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import helper\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussians(N0,N1,mu0,mu1,s):\n",
    "    # N0: Cantidad de muestras pertenecientes a la clase 0\n",
    "    # N1: Cantidad de muestras pertenecientes a la clase 1\n",
    "    # mu0: Media de las muestras pertenecientes a 0\n",
    "    # mu1: Media de las muestras pertenecientes a 1\n",
    "    # s: Desvío estandar de los predictores. Los predictores son independientes.\n",
    "    sigma=[[s,0],[0,s]]\n",
    "    np.random.seed(231)\n",
    "    X=np.vstack([np.random.multivariate_normal(mu0, sigma,N0),np.random.multivariate_normal(mu1, sigma,N1)])\n",
    "    y=np.hstack([np.zeros(N0),np.ones(N1)])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intepretación del dataset\n",
    "\n",
    "Supongamos que los valores de los predictores de este dataset son los valores de concentración en sangre de dos indicadores.  \n",
    "En el siguiente gráfico los puntos azules representan valores de los indicadores en personas enfermas.  \n",
    "Los puntos rojos representan valores de los indicadores en personas sanas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=generate_gaussians(N0=1000,N1=1000,mu0=[2,5],mu1=[3,3],s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plotBoundary(X_train,y_train)\n",
    "helper.plotBoundary(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribir una función plot_metrics que reciba:\n",
    "\n",
    "- y_true: Las anotaciones de las clases de cada observacion. El ground truth.\n",
    "- y_proba: La probabilidad que dió el clasificador de que cada observación pertenezca a la clase 1\n",
    "- num: cantidad de valores que tomará el threshold\n",
    "- plot_metrics: si es true, se graficarán las métricas en función del threshold\n",
    "- plot_ROC: si es true, se graficará la curva ROC\n",
    "\n",
    "La función devuelve la binary cross entropy y el área bajo la curva ROC para los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La siguiente función grafica las métricas de la matriz de confunsión y la curva ROC.\n",
    "# Devuelve el area bajo la curva ROC y la loss\n",
    "def plot_metrics(y_true,y_proba,num=50,plot_metrics=False,plot_ROC=False):\n",
    "    P= #cantidad de observaciones pertenecientes a la clase P (1)\n",
    "    N= #cantidad de observaciones pertenecientes a la clase N (0)\n",
    "    if plot_metrics:\n",
    "        cond_pos= #Proporción de observaciones positivas (PRIORI)\n",
    "        cond_neg= #Proporción de observaciones negativas (PRIORI)\n",
    "        # Reserva de espacio para las métricas\n",
    "        accuracy=np.zeros(num)\n",
    "        specificity=np.zeros(num)\n",
    "        ppv=np.zeros(num)\n",
    "        npv=np.zeros(num)\n",
    "        fnr=np.zeros(num)\n",
    "    sensitivity=np.zeros(num+2) # Se reservan dos lugares mas, para fijar lo thresholds en cero y uno\n",
    "    fpr=np.zeros(num+2)  # Se reservan dos lugares mas, para fijar lo thresholds en cero y uno\n",
    "    thresholds=np.linspace(0.01,0.99,num)\n",
    "    for idx,threshold in enumerate(thresholds):\n",
    "        y_pred=1*(y_proba>threshold)\n",
    "        conf_matrix=metrics.confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        TN=conf_matrix[0,0]\n",
    "        FN=conf_matrix[1,0]\n",
    "        FP=conf_matrix[0,1]\n",
    "        TP=conf_matrix[1,1]\n",
    "        sensitivity[idx+1]= #Completar\n",
    "        fpr[idx+1]= #Completar\n",
    "        if(plot_metrics):\n",
    "            accuracy[idx]= #Completar\n",
    "            specificity[idx]= #Completar\n",
    "            ppv[idx]= #Completar\n",
    "            npv[idx]= #Completar\n",
    "            fnr[idx]= #Completar\n",
    "    # Completo los valores de los extremos.\n",
    "    sensitivity[0]=1 \n",
    "    sensitivity[-1]=0\n",
    "    fpr[0]=1\n",
    "    fpr[-1]=0\n",
    "    roc_auc = metrics.auc(fpr, sensitivity)\n",
    "    if(plot_metrics):\n",
    "        # Gráfica de las métricas en función del threshold\n",
    "        plt.figure(figsize=[15,10])\n",
    "        plt.plot(np.linspace(0,1,num),accuracy, label='Accuracy')\n",
    "        plt.plot(np.linspace(0,1,num),sensitivity[1:-1], label='Sensitivity or True Positive Rate or Recall')\n",
    "        plt.plot(np.linspace(0,1,num),specificity, label='Specificity')\n",
    "        plt.plot(np.linspace(0,1,num),ppv, label='Positive Predictive Value or Precision ')\n",
    "        plt.plot(np.linspace(0,1,num),npv, label='Negative Predictive Value')\n",
    "        plt.plot(np.linspace(0,1,num),fnr, label='False Negative Rate or Miss Rate')\n",
    "        plt.plot(np.linspace(0,1,num),fpr[1:-1], label='False Positive Rate or Fall-out')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Metric')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.show()\n",
    "    if(plot_ROC):\n",
    "        plt.plot(fpr,sensitivity,label=\"ROC curve. Area={}\".format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    cant_obs=len(y_true)\n",
    "    epsilon=1e-9 # este valor está para evitar el logaritmo de cero\n",
    "    loss=  #Completar\n",
    "    return roc_auc,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora utilice el siguiente código para generar observaciones y graficar las métricas solicitadas para el caso: \n",
    "\n",
    "$$N1=10000,N2=2000,mu1=[-4,4],mu2=[4,-4],s=20$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=generate_gaussians(N0=10000,N1=2000,mu0=[-4,4],mu1=[4,-4],s=20)\n",
    "clf=SGDClassifier(loss='log',penalty=None,max_iter=1000,tol=1e-6,learning_rate='adaptive',eta0=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_train_pred_proba=clf.predict_proba(X_train)[:,1]\n",
    "plot_metrics(y_train,y_train_pred_proba,plot_metrics=True,num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas:\n",
    "\n",
    "- Cuánto vale la binary crossentropy?  \n",
    "- Cuánto vale el área bajo la curva ROC?  \n",
    "- Si elegimos un threshold de 0.2:  \n",
    "    -  ¿Cuánta gente que se haga el test y le haya dado positivo,no tiene la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de negativo, tiene en realidad la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de positivo, tiene efectivamente la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de negativo, no tiene la enfermedad?\n",
    "    \n",
    "- Si elegimos un threshold de 0.2:  \n",
    "    -  ¿Cuánta gente que se haga el test y le haya dado positivo, no tiene la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de negativo, tiene en realidad la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de positivo, tiene efectivamente la enfermedad?\n",
    "    -  ¿Cuánta gente que cuyo test de negativo, no tiene la enfermedad?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema (se alienta la resolución en conjunto):\n",
    "\n",
    "Usted es empleado de un sistema de salud que utiliza el test anterior en pacientes para detectar una enfermedad. \n",
    "\n",
    "- El costo de realizar este test (de descarte) es despreciable para el sistema de salud.  \n",
    "- Si alguien se hace el test de descarte y da positivo, tiene que realizarse un test mas caro pero definitivo (detección perfecta) cuyo costo es 2500 pesos. \n",
    "- Si el test definitivo da positivo, el paciente deberá realizarse un tratamiento (de detección temprana) cuyo costo es de 2500 pesos.  \n",
    "- Si el test definitivo da negativo, el paciente no deberá realizarse ningún tratamiento, ya que está sano.\n",
    "- Si el test de descarte da negativo, pero el paciente estaba enfermo, mas adelante la enfermedad se detectará y deberá realizar un tratamiento (de detección tardía) cuyo costo es de 9500 pesos.\n",
    "- Si el test de descarte da negativo, y el paciente no estaba enfermo, no hay ningún costo asociado para la empresa.\n",
    "\n",
    "Pensando solamente en el costo total para el sistema de salud, es decir, cuánto dinero promedio se gasta por paciente, ¿cuál es valor de threshold que minimiza este costo? \n",
    "\n",
    "Recomendación: Exprese el costo en función de las distintas métricas estudiadas en ingréselo en la función anterior como una métrica mas. Luego utilice argmin sobre el arreglo de esta nueva métrica para encontrar el threshold que minimiza el costo.\n",
    "\n",
    "¿Cuánto vale la sensibilidad, la especificidad, el VPP y el VPN del test de descarte para este threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,12])\n",
    "auc_rocs_train=list()\n",
    "losses_train=list()\n",
    "auc_rocs_test=list()\n",
    "losses_test=list()\n",
    "plots=4\n",
    "aux=5\n",
    "res=plots*aux\n",
    "grid = plt.GridSpec(plots-1, plots, wspace=0.4, hspace=0.3)\n",
    "sigmas=np.geomspace(3,50,res)\n",
    "plot_number=0\n",
    "for idx,s in enumerate(sigmas):\n",
    "    X_train, X_test, y_train, y_test=generate_gaussians(N1=1000,N2=20000,mu1=[-4,4],mu2=[4,-4],s=s)\n",
    "    clf=SGDClassifier(loss='log',penalty=None,max_iter=1000,tol=1e-6,learning_rate='adaptive',eta0=0.1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_train_pred_proba=clf.predict_proba(X_train)[:,1]\n",
    "    roc,loss=plot_metrics(y_train,y_train_pred_proba,plot_ROC=False,num=10)\n",
    "    auc_rocs_train.append(roc)\n",
    "    losses_train.append(loss)\n",
    "    y_test_pred_proba=clf.predict_proba(X_test)[:,1]\n",
    "    roc,loss=plot_metrics(y_test,y_test_pred_proba,num=10)\n",
    "    auc_rocs_test.append(roc)\n",
    "    losses_test.append(loss)\n",
    "    if idx % aux == 0:\n",
    "        ax=plt.subplot(grid[(plots-2):plots-1, plot_number:(plot_number+1)])\n",
    "        helper.plotBoundary(X_test,y_test,clf,ax=ax,mins=[-15,-15],maxs=[15,15])\n",
    "        ax.set_xlim([-15,15])\n",
    "        ax.set_ylim([-15,15])\n",
    "        acc=clf.score(X_test,y_test)\n",
    "        ax.set_title(\"sigma={:.2f}, test_accuracy={:.2f}\".format(s,acc))\n",
    "        plot_number += 1\n",
    "plt.subplot(grid[:-1,:])\n",
    "plt.plot(auc_rocs_train,losses_train,label=\"train\",c=\"b\")\n",
    "plt.plot(auc_rocs_test,losses_test,label=\"test\",c=\"r\")\n",
    "plt.scatter(auc_rocs_train,losses_train,c=\"b\",label=\"train_sigma\")\n",
    "plt.scatter(auc_rocs_test,losses_test,c=\"r\",label=\"test_sigma\")\n",
    "for idx,s in enumerate(sigmas):\n",
    "    plt.text(auc_rocs_train[idx],losses_train[idx],\"{:.2f}\".format(s),color=\"b\")\n",
    "    plt.text(auc_rocs_test[idx],losses_test[idx],\"{:.2f}\".format(s),color=\"r\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"AUC_ROC\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
